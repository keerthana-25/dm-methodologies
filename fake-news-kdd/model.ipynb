{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff57b4c0-982c-4d8b-aae7-3d559ecf36a8",
   "metadata": {},
   "source": [
    "1. Selection\n",
    "The Selection phase in KDD is about deciding which data sources are relevant to your project goal.\n",
    "For this project our goal is to detect whether a news is fake or not.\n",
    "\n",
    "We are given two datasets: Fake.csv and True.csv\n",
    "We load these datasets and look for some initial understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745c6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dae795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data\n",
    "df_fake = pd.read_csv('./datasets/Fake.csv')\n",
    "df_true = pd.read_csv('./datasets/True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c8dde",
   "metadata": {},
   "source": [
    "2. Preprocessing\n",
    "The goal of Pre-processing is to clean the raw, selected data to make it suitable for the next stages. Real-world data is often messy, containing missing values, inconsistent formats, and irrelevant information. We must fix this before the model can learn effectively.\n",
    "\n",
    "This is classification problem, and the model needs a label to do supervised learning on it. So we add anothe column to let us know what kind of data it is. A label of '1' indicates that it is a fake news and '0' otherwise.\n",
    "We then combine the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32dfb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake['label'] = 1\n",
    "df_true['label'] = 0\n",
    "\n",
    "df_combined = pd.concat([df_fake, df_true], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b73ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a47285a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combined Data Head (First 5 Rows) ---\n",
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  label  \n",
      "0  December 31, 2017      1  \n",
      "1  December 31, 2017      1  \n",
      "2  December 30, 2017      1  \n",
      "3  December 29, 2017      1  \n",
      "4  December 25, 2017      1  \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Combined Data Head (First 5 Rows) ---\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c19d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Data Information ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Combined Data Information ---\")\n",
    "print(df_combined.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a7ee7",
   "metadata": {},
   "source": [
    "We check if the dataset has some missing values in it.\n",
    "Our dataset is clean and has no missingness. Hence, we need not impute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b45ee866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      0\n",
       "text       0\n",
       "subject    0\n",
       "date       0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919bbad",
   "metadata": {},
   "source": [
    "Check if the dataset has some duplicates. Have duplicates can make the model more bias to the same set of data and also increase computational cost.\n",
    "Smaller the dataset, better is the prediction. There are about 209 duplicate data in our dataset. We simply remove these duplicate data and proceed to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44d906a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(209)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "720b503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95cbcde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44689, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bacc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    23478\n",
      "0    21211\n",
      "Name: count, dtype: int64\n",
      "Imbalance ratio (Fake:True) = 1.107 : 1\n"
     ]
    }
   ],
   "source": [
    "print(df_combined['label'].value_counts())\n",
    "print(f\"Imbalance ratio (Fake:True) = {df_combined['label'].value_counts()[1] / df_combined['label'].value_counts()[0]:.3f} : 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810749f",
   "metadata": {},
   "source": [
    "We determine if the dataset is imbalaned. The ratio of fake to true is 1.107:1 seems fairly balanced, which is a good thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5374ace",
   "metadata": {},
   "source": [
    "3. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e003c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skleant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskleant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      4\u001b[0m     df_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     df_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mdf_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skleant'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_combined['text'],\n",
    "    df_combined['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_combined['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e938ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I) # Remove extra white space from text\n",
    "\n",
    "    text = re.sub(r'\\W', ' ', str(text)) # Remove all the special characters from text\n",
    "\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text) # Remove all single characters from text\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove any character that isn't alphabetical\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    Words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
